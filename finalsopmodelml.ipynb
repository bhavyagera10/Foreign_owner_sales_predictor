{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.1470380e+04 8.2140000e+01 1.6894150e+04 1.1102170e+04 2.1000000e+00\n",
      "  1.5894123e+05]\n",
      " [4.4144000e+04 7.3550000e+01 3.5163000e+04 5.8340000e+03 1.5700000e+00\n",
      "  5.2975700e+05]\n",
      " [2.1544650e+04 7.6100000e+01 7.1320200e+03 3.6641800e+03 1.2300000e+00\n",
      "  5.0320540e+04]\n",
      " ...\n",
      " [          nan           nan           nan           nan           nan\n",
      "  1.6774450e+04]\n",
      " [          nan           nan           nan           nan           nan\n",
      "  1.6680850e+04]\n",
      " [          nan           nan           nan           nan           nan\n",
      "  1.6348190e+04]]\n",
      "[[527692.69]\n",
      " [371019.  ]\n",
      " [297275.05]\n",
      " [275197.42]\n",
      " [242868.65]\n",
      " [123170.  ]\n",
      " [109609.42]\n",
      " [ 98972.05]\n",
      " [ 90307.43]\n",
      " [ 86987.86]\n",
      " [ 86020.3 ]\n",
      " [ 76727.  ]\n",
      " [ 75126.3 ]\n",
      " [ 73107.  ]\n",
      " [ 70610.71]\n",
      " [ 69202.76]\n",
      " [ 69202.76]\n",
      " [ 66967.31]\n",
      " [ 63401.19]\n",
      " [ 62062.14]\n",
      " [ 54985.77]\n",
      " [ 53614.  ]\n",
      " [ 51310.25]\n",
      " [ 49974.11]\n",
      " [ 49608.  ]\n",
      " [ 48123.8 ]\n",
      " [ 46810.34]\n",
      " [ 45749.16]\n",
      " [ 44995.65]\n",
      " [ 43348.04]\n",
      " [ 42670.89]\n",
      " [ 41338.39]\n",
      " [ 40767.81]\n",
      " [ 38644.  ]\n",
      " [ 38395.43]\n",
      " [ 38224.  ]\n",
      " [ 36858.8 ]\n",
      " [ 35703.5 ]\n",
      " [ 34119.12]\n",
      " [ 34066.66]\n",
      " [ 33650.54]\n",
      " [ 30348.95]\n",
      " [ 30249.96]\n",
      " [ 29624.75]\n",
      " [ 29054.95]\n",
      " [ 28979.44]\n",
      " [ 28842.  ]\n",
      " [ 28496.77]\n",
      " [ 27715.97]\n",
      " [ 27219.6 ]\n",
      " [ 26012.  ]\n",
      " [ 25309.72]\n",
      " [ 23943.21]\n",
      " [ 23286.53]\n",
      " [ 22638.57]\n",
      " [ 22261.15]\n",
      " [ 22071.24]\n",
      " [ 21118.  ]\n",
      " [ 20891.6 ]\n",
      " [ 20550.43]\n",
      " [ 20164.9 ]\n",
      " [ 19916.25]\n",
      " [ 19894.12]\n",
      " [ 19184.81]\n",
      " [ 19069.97]\n",
      " [ 18209.92]\n",
      " [ 17631.26]\n",
      " [ 17383.97]\n",
      " [ 17355.02]\n",
      " [ 16851.21]\n",
      " [ 16391.78]\n",
      " [ 15837.  ]\n",
      " [ 15656.65]\n",
      " [ 15541.3 ]\n",
      " [ 15522.44]\n",
      " [ 15407.35]\n",
      " [ 14330.63]\n",
      " [ 14081.15]\n",
      " [ 13734.96]\n",
      " [ 13683.8 ]\n",
      " [ 13495.65]\n",
      " [ 13203.85]\n",
      " [ 12977.52]\n",
      " [ 12883.88]\n",
      " [ 12729.23]\n",
      " [ 12585.01]\n",
      " [ 12374.01]\n",
      " [ 12368.9 ]\n",
      " [ 12353.77]\n",
      " [ 12257.9 ]\n",
      " [ 12257.89]\n",
      " [ 12245.24]\n",
      " [ 12152.67]\n",
      " [ 12084.6 ]\n",
      " [ 12079.76]\n",
      " [ 11948.17]\n",
      " [ 11722.  ]\n",
      " [ 11667.88]\n",
      " [ 11499.32]\n",
      " [ 11419.02]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]\n",
      " [      nan]]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('dataf.csv')\n",
    "X = dataset.iloc[0:, 2:8].values\n",
    "#X = X.replace(',', '')\n",
    "#for c in X.split(\",\"):\n",
    "#X=[float(c) for c in X.split(',')]\n",
    "  #print float(c)\n",
    "#y = dataset.iloc[:, 3].values\n",
    "#dataset.['Company Name']=dataset.['Company Name'].astype(float)\n",
    "#y = dataset.iloc[:, 1].values\n",
    "y = dataset.iloc[:, 1:2].values\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.1470380e+04 8.2140000e+01 1.6894150e+04 1.1102170e+04 2.1000000e+00\n",
      "  1.5894123e+05]\n",
      " [4.4144000e+04 7.3550000e+01 3.5163000e+04 5.8340000e+03 1.5700000e+00\n",
      "  5.2975700e+05]\n",
      " [2.1544650e+04 7.6100000e+01 7.1320200e+03 3.6641800e+03 1.2300000e+00\n",
      "  5.0320540e+04]\n",
      " ...\n",
      " [5.2883223e+03 6.2628300e+01 4.3748585e+03 4.4213657e+03 1.9752100e+01\n",
      "  1.6774450e+04]\n",
      " [5.2883223e+03 6.2628300e+01 4.3748585e+03 4.4213657e+03 1.9752100e+01\n",
      "  1.6680850e+04]\n",
      " [5.2883223e+03 6.2628300e+01 4.3748585e+03 4.4213657e+03 1.9752100e+01\n",
      "  1.6348190e+04]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "imputer=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "imputer=imputer.fit(X[:,0:6])\n",
    "X[:,0:6]=imputer.transform(X[:,0:6])\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[527692.69 ]\n",
      " [371019.   ]\n",
      " [297275.05 ]\n",
      " [275197.42 ]\n",
      " [242868.65 ]\n",
      " [123170.   ]\n",
      " [109609.42 ]\n",
      " [ 98972.05 ]\n",
      " [ 90307.43 ]\n",
      " [ 86987.86 ]\n",
      " [ 86020.3  ]\n",
      " [ 76727.   ]\n",
      " [ 75126.3  ]\n",
      " [ 73107.   ]\n",
      " [ 70610.71 ]\n",
      " [ 69202.76 ]\n",
      " [ 69202.76 ]\n",
      " [ 66967.31 ]\n",
      " [ 63401.19 ]\n",
      " [ 62062.14 ]\n",
      " [ 54985.77 ]\n",
      " [ 53614.   ]\n",
      " [ 51310.25 ]\n",
      " [ 49974.11 ]\n",
      " [ 49608.   ]\n",
      " [ 48123.8  ]\n",
      " [ 46810.34 ]\n",
      " [ 45749.16 ]\n",
      " [ 44995.65 ]\n",
      " [ 43348.04 ]\n",
      " [ 42670.89 ]\n",
      " [ 41338.39 ]\n",
      " [ 40767.81 ]\n",
      " [ 38644.   ]\n",
      " [ 38395.43 ]\n",
      " [ 38224.   ]\n",
      " [ 36858.8  ]\n",
      " [ 35703.5  ]\n",
      " [ 34119.12 ]\n",
      " [ 34066.66 ]\n",
      " [ 33650.54 ]\n",
      " [ 30348.95 ]\n",
      " [ 30249.96 ]\n",
      " [ 29624.75 ]\n",
      " [ 29054.95 ]\n",
      " [ 28979.44 ]\n",
      " [ 28842.   ]\n",
      " [ 28496.77 ]\n",
      " [ 27715.97 ]\n",
      " [ 27219.6  ]\n",
      " [ 26012.   ]\n",
      " [ 25309.72 ]\n",
      " [ 23943.21 ]\n",
      " [ 23286.53 ]\n",
      " [ 22638.57 ]\n",
      " [ 22261.15 ]\n",
      " [ 22071.24 ]\n",
      " [ 21118.   ]\n",
      " [ 20891.6  ]\n",
      " [ 20550.43 ]\n",
      " [ 20164.9  ]\n",
      " [ 19916.25 ]\n",
      " [ 19894.12 ]\n",
      " [ 19184.81 ]\n",
      " [ 19069.97 ]\n",
      " [ 18209.92 ]\n",
      " [ 17631.26 ]\n",
      " [ 17383.97 ]\n",
      " [ 17355.02 ]\n",
      " [ 16851.21 ]\n",
      " [ 16391.78 ]\n",
      " [ 15837.   ]\n",
      " [ 15656.65 ]\n",
      " [ 15541.3  ]\n",
      " [ 15522.44 ]\n",
      " [ 15407.35 ]\n",
      " [ 14330.63 ]\n",
      " [ 14081.15 ]\n",
      " [ 13734.96 ]\n",
      " [ 13683.8  ]\n",
      " [ 13495.65 ]\n",
      " [ 13203.85 ]\n",
      " [ 12977.52 ]\n",
      " [ 12883.88 ]\n",
      " [ 12729.23 ]\n",
      " [ 12585.01 ]\n",
      " [ 12374.01 ]\n",
      " [ 12368.9  ]\n",
      " [ 12353.77 ]\n",
      " [ 12257.9  ]\n",
      " [ 12257.89 ]\n",
      " [ 12245.24 ]\n",
      " [ 12152.67 ]\n",
      " [ 12084.6  ]\n",
      " [ 12079.76 ]\n",
      " [ 11948.17 ]\n",
      " [ 11722.   ]\n",
      " [ 11667.88 ]\n",
      " [ 11499.32 ]\n",
      " [ 11419.02 ]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]\n",
      " [ 49092.549]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "imputer=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "imputer=imputer.fit(y[:,0:1])\n",
    "y[:,0:1]=imputer.transform(y[:,0:1])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "sc_y = StandardScaler()\n",
    "y_train = sc_y.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>527692.69</td>\n",
       "      <td>71470.38</td>\n",
       "      <td>82.14</td>\n",
       "      <td>16894.15</td>\n",
       "      <td>11102.17</td>\n",
       "      <td>2.10</td>\n",
       "      <td>158941.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>371019.00</td>\n",
       "      <td>44144.00</td>\n",
       "      <td>73.55</td>\n",
       "      <td>35163.00</td>\n",
       "      <td>5834.00</td>\n",
       "      <td>1.57</td>\n",
       "      <td>529757.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>297275.05</td>\n",
       "      <td>21544.65</td>\n",
       "      <td>76.10</td>\n",
       "      <td>7132.02</td>\n",
       "      <td>3664.18</td>\n",
       "      <td>1.23</td>\n",
       "      <td>50320.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>275197.42</td>\n",
       "      <td>20193.42</td>\n",
       "      <td>77.84</td>\n",
       "      <td>6028.66</td>\n",
       "      <td>2938.48</td>\n",
       "      <td>1.07</td>\n",
       "      <td>39869.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>109609.42</td>\n",
       "      <td>7749.17</td>\n",
       "      <td>46.42</td>\n",
       "      <td>26715.79</td>\n",
       "      <td>12113.03</td>\n",
       "      <td>11.05</td>\n",
       "      <td>185075.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>90307.43</td>\n",
       "      <td>7988.02</td>\n",
       "      <td>43.02</td>\n",
       "      <td>11749.89</td>\n",
       "      <td>4779.89</td>\n",
       "      <td>5.29</td>\n",
       "      <td>201121.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>86020.30</td>\n",
       "      <td>3325.70</td>\n",
       "      <td>57.19</td>\n",
       "      <td>7500.60</td>\n",
       "      <td>3254.90</td>\n",
       "      <td>3.78</td>\n",
       "      <td>42713.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>76727.00</td>\n",
       "      <td>10599.00</td>\n",
       "      <td>46.03</td>\n",
       "      <td>8259.00</td>\n",
       "      <td>1400.00</td>\n",
       "      <td>1.82</td>\n",
       "      <td>58826.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>75126.30</td>\n",
       "      <td>2321.91</td>\n",
       "      <td>30.56</td>\n",
       "      <td>6025.67</td>\n",
       "      <td>1778.37</td>\n",
       "      <td>2.37</td>\n",
       "      <td>39494.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>70610.71</td>\n",
       "      <td>11255.34</td>\n",
       "      <td>84.40</td>\n",
       "      <td>10533.19</td>\n",
       "      <td>5131.06</td>\n",
       "      <td>7.27</td>\n",
       "      <td>91939.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>69202.76</td>\n",
       "      <td>4662.00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>2020.60</td>\n",
       "      <td>4273.10</td>\n",
       "      <td>6.17</td>\n",
       "      <td>33793.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>69202.76</td>\n",
       "      <td>4662.00</td>\n",
       "      <td>50.57</td>\n",
       "      <td>2020.60</td>\n",
       "      <td>4273.10</td>\n",
       "      <td>6.17</td>\n",
       "      <td>33793.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>66967.31</td>\n",
       "      <td>19441.80</td>\n",
       "      <td>80.48</td>\n",
       "      <td>2178.82</td>\n",
       "      <td>8830.34</td>\n",
       "      <td>13.19</td>\n",
       "      <td>69777.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>53614.00</td>\n",
       "      <td>3839.27</td>\n",
       "      <td>33.34</td>\n",
       "      <td>4796.04</td>\n",
       "      <td>2980.22</td>\n",
       "      <td>5.56</td>\n",
       "      <td>30738.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>45749.16</td>\n",
       "      <td>11394.46</td>\n",
       "      <td>75.46</td>\n",
       "      <td>1205.43</td>\n",
       "      <td>1981.71</td>\n",
       "      <td>4.33</td>\n",
       "      <td>61758.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>44995.65</td>\n",
       "      <td>7587.24</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12464.32</td>\n",
       "      <td>2728.44</td>\n",
       "      <td>6.06</td>\n",
       "      <td>51638.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>35703.50</td>\n",
       "      <td>3273.62</td>\n",
       "      <td>54.60</td>\n",
       "      <td>2455.72</td>\n",
       "      <td>1926.01</td>\n",
       "      <td>5.39</td>\n",
       "      <td>40557.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0        0.1       0.2    0.3       0.4       0.5    0.6        0.7\n",
       "0   0.0  527692.69  71470.38  82.14  16894.15  11102.17   2.10  158941.23\n",
       "1   0.0  371019.00  44144.00  73.55  35163.00   5834.00   1.57  529757.00\n",
       "2   0.0  297275.05  21544.65  76.10   7132.02   3664.18   1.23   50320.54\n",
       "3   0.0  275197.42  20193.42  77.84   6028.66   2938.48   1.07   39869.30\n",
       "6   0.0  109609.42   7749.17  46.42  26715.79  12113.03  11.05  185075.44\n",
       "8   0.0   90307.43   7988.02  43.02  11749.89   4779.89   5.29  201121.02\n",
       "10  0.0   86020.30   3325.70  57.19   7500.60   3254.90   3.78   42713.40\n",
       "11  0.0   76727.00  10599.00  46.03   8259.00   1400.00   1.82   58826.00\n",
       "12  0.0   75126.30   2321.91  30.56   6025.67   1778.37   2.37   39494.57\n",
       "14  0.0   70610.71  11255.34  84.40  10533.19   5131.06   7.27   91939.23\n",
       "15  0.0   69202.76   4662.00  50.57   2020.60   4273.10   6.17   33793.67\n",
       "16  0.0   69202.76   4662.00  50.57   2020.60   4273.10   6.17   33793.67\n",
       "17  0.0   66967.31  19441.80  80.48   2178.82   8830.34  13.19   69777.05\n",
       "21  0.0   53614.00   3839.27  33.34   4796.04   2980.22   5.56   30738.24\n",
       "27  0.0   45749.16  11394.46  75.46   1205.43   1981.71   4.33   61758.83\n",
       "28  0.0   44995.65   7587.24  50.57  12464.32   2728.44   6.06   51638.94\n",
       "37  0.0   35703.50   3273.62  54.60   2455.72   1926.01   5.39   40557.27"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32857583 -0.40549641  0.2026742   0.03268239 -0.01302966 -0.25686761]\n",
      " [-0.4087172  -0.5258173  -0.89892213 -0.72224693 -0.85661095  0.00179126]\n",
      " [-0.66605151 -1.36528155 -0.35795576  0.03268239 -0.01302966  0.00179126]\n",
      " ...\n",
      " [-0.46061365  1.62465781  0.00879584  0.03268239 -0.01302966  0.00179126]\n",
      " [-0.04252141  0.00959676  0.00879584 -0.26300988 -0.60196219  0.00179126]\n",
      " [-0.04252141  0.00959676 -0.84752706 -0.71180444  0.82353194  0.00179126]]\n",
      "[[-2.00096238e-01]\n",
      " [-6.20083068e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-6.47822603e-01]\n",
      " [ 3.62637867e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [ 3.31504925e-02]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-3.78067384e-01]\n",
      " [-6.25875634e-01]\n",
      " [ 3.56066420e+00]\n",
      " [-7.68807521e-03]\n",
      " [-5.44964408e-01]\n",
      " [-7.68807521e-03]\n",
      " [-4.70808659e-01]\n",
      " [-5.87042091e-01]\n",
      " [-4.97145462e-02]\n",
      " [-6.74464245e-01]\n",
      " [-2.92049912e-01]\n",
      " [ 4.34533749e-01]\n",
      " [-7.68807521e-03]\n",
      " [-6.85991739e-01]\n",
      " [ 1.80386285e-03]\n",
      " [-1.25941778e-01]\n",
      " [-7.68807521e-03]\n",
      " [-5.40385563e-01]\n",
      " [-5.05280652e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [ 2.31144626e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-4.94833372e-01]\n",
      " [-7.68807521e-03]\n",
      " [-6.63198610e-01]\n",
      " [-4.45644622e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-6.83853410e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-3.52848102e-01]\n",
      " [ 3.88565015e-01]\n",
      " [-6.92559863e-02]\n",
      " [-4.32712261e-01]\n",
      " [-7.68807521e-03]\n",
      " [ 1.00834537e-01]\n",
      " [-7.68807521e-03]\n",
      " [-3.80598317e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-5.45371928e-01]\n",
      " [-7.68807521e-03]\n",
      " [ 4.56254834e+00]\n",
      " [-5.33286097e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-3.66184115e-01]\n",
      " [-7.68807521e-03]\n",
      " [ 6.72329861e-01]\n",
      " [-7.68807521e-03]\n",
      " [-6.25528331e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-6.99960670e-01]\n",
      " [ 4.15599273e+00]\n",
      " [-6.89182844e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [ 8.80564801e+00]\n",
      " [-6.89271971e-01]\n",
      " [-6.91695178e-01]\n",
      " [-6.01406572e-01]\n",
      " [-4.10474523e-01]\n",
      " [-4.01333958e-01]\n",
      " [-6.79967883e-01]\n",
      " [-7.68807521e-03]\n",
      " [ 8.54571309e-03]\n",
      " [-6.58791759e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [ 1.10671929e+00]\n",
      " [-5.92129001e-01]\n",
      " [-6.77312097e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-6.86224687e-01]\n",
      " [-7.68807521e-03]\n",
      " [ 5.01195402e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-2.07830463e-01]\n",
      " [-5.22834397e-01]\n",
      " [-5.76386170e-01]\n",
      " [ 5.92053000e+00]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-3.54670985e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [ 3.21472455e-01]\n",
      " [-2.83421095e-01]\n",
      " [-7.68807521e-03]\n",
      " [-4.82901304e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-2.04673610e-01]\n",
      " [-8.31317383e-02]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-1.50479528e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-1.60986657e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-1.13472182e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.01439381e-01]\n",
      " [-6.72739882e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-6.59733861e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-6.23404181e-01]\n",
      " [-6.52416732e-01]\n",
      " [-2.55274150e-02]\n",
      " [-7.68807521e-03]\n",
      " [-6.68572055e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-2.84387136e-01]\n",
      " [-7.68807521e-03]\n",
      " [-5.27003512e-01]\n",
      " [-7.68807521e-03]\n",
      " [-6.84226126e-01]\n",
      " [-7.68807521e-03]\n",
      " [-6.09866894e-01]\n",
      " [-6.83947510e-01]\n",
      " [-2.32970377e-01]\n",
      " [ 7.55736371e-02]\n",
      " [-7.68807521e-03]\n",
      " [ 6.90147306e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-5.91595892e-01]\n",
      " [-7.68807521e-03]\n",
      " [-7.68807521e-03]\n",
      " [-3.86955666e-01]\n",
      " [-7.68807521e-03]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#np.where(x.values >= np.finfo(np.float64).max)\n",
    "regressor = LinearRegression()\n",
    "np.any(np.isnan(X_train))\n",
    "np.all(np.isfinite(X_train))\n",
    "np.any(np.isnan(y_train))\n",
    "np.all(np.isfinite(y_train))\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "regressor.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels import api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.709</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   136.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 17 May 2020</td> <th>  Prob (F-statistic):</th> <td>4.63e-59</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>04:00:45</td>     <th>  Log-Likelihood:    </th> <td> -2670.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   230</td>      <th>  AIC:               </th> <td>   5352.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   225</td>      <th>  BIC:               </th> <td>   5369.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 8567.2410</td> <td> 8062.264</td> <td>    1.063</td> <td> 0.289</td> <td>-7319.961</td> <td> 2.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    6.3389</td> <td>    0.353</td> <td>   17.957</td> <td> 0.000</td> <td>    5.643</td> <td>    7.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> -107.2990</td> <td>  124.732</td> <td>   -0.860</td> <td> 0.391</td> <td> -353.092</td> <td>  138.494</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    1.5234</td> <td>    0.606</td> <td>    2.514</td> <td> 0.013</td> <td>    0.329</td> <td>    2.718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    1.5965</td> <td>    0.386</td> <td>    4.140</td> <td> 0.000</td> <td>    0.837</td> <td>    2.356</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>84.909</td> <th>  Durbin-Watson:     </th> <td>   0.765</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 791.805</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.144</td> <th>  Prob(JB):          </th> <td>1.15e-172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.797</td> <th>  Cond. No.          </th> <td>4.70e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.7e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.709\n",
       "Model:                            OLS   Adj. R-squared:                  0.703\n",
       "Method:                 Least Squares   F-statistic:                     136.8\n",
       "Date:                Sun, 17 May 2020   Prob (F-statistic):           4.63e-59\n",
       "Time:                        04:00:45   Log-Likelihood:                -2670.8\n",
       "No. Observations:                 230   AIC:                             5352.\n",
       "Df Residuals:                     225   BIC:                             5369.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       8567.2410   8062.264      1.063      0.289   -7319.961    2.45e+04\n",
       "x1             6.3389      0.353     17.957      0.000       5.643       7.034\n",
       "x2          -107.2990    124.732     -0.860      0.391    -353.092     138.494\n",
       "x3             1.5234      0.606      2.514      0.013       0.329       2.718\n",
       "x4             1.5965      0.386      4.140      0.000       0.837       2.356\n",
       "==============================================================================\n",
       "Omnibus:                       84.909   Durbin-Watson:                   0.765\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              791.805\n",
       "Skew:                           1.144   Prob(JB):                    1.15e-172\n",
       "Kurtosis:                      11.797   Cond. No.                     4.70e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.7e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.append(arr = np.ones((230, 1)).astype(int), values = X, axis = 1)\n",
    "X_opt = X[:, [0, 1, 2, 3, 4]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "#X_opt = X[:, [0, 2, 3, 4, 5]]\n",
    "#regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "#regressor_OLS.summary()\n",
    "#X_opt = X[:, [0, 3, 4, 5]]\n",
    "#regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "#regressor_OLS.summary()\n",
    "#X_opt = X[:, [0, 3, 5]]\n",
    "#regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "#regressor_OLS.summary()\n",
    "#X_opt = X[:, [0, 3]]\n",
    "#regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "#regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
